{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d67a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as xes_converter\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "from pm4py.objects.log.obj import EventLog, Trace, Event\n",
    "import math\n",
    "import csv\n",
    "from CminSampler import CminSampler\n",
    "import constants\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import format_logistic as fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e46f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dfs(df_path: str) -> []:\n",
    "    '''reads all csv files for sampling'''\n",
    "    \n",
    "    # Use os.fchdir() method to change the dir\n",
    "    fd = os.open(df_path, os.O_RDONLY )\n",
    "    os.fchdir(fd)\n",
    "    \n",
    "    # use glob to get all the csv files in the folder\n",
    "    path = os.getcwd()\n",
    "    csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    \n",
    "    dataframes = []\n",
    "    \n",
    "    # loop over the list of csv files\n",
    "    for f in csv_files:\n",
    "        \n",
    "        # get src and dest loc from the file name\n",
    "        src_dest_loc = f.split('/')[-1].split('_')[1:]\n",
    "        src_loc = src_dest_loc[0]\n",
    "        dest_loc = src_dest_loc[1].split('.')[0]\n",
    "        \n",
    "        # read the csv file\n",
    "        df = pd.read_csv(f)\n",
    "        # add source and destination location\n",
    "        df[constants.src_dest_attributes[0]] = src_loc\n",
    "        df[constants.src_dest_attributes[1]] = dest_loc\n",
    "        dataframes.append(df)\n",
    "        \n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f52e84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_logs(dataframes: []):\n",
    "    '''converts the dataframes into event logs'''\n",
    "    \n",
    "    # Initialize an empty list for the logs\n",
    "    logs = []\n",
    "    for dataframe in dataframes:\n",
    "        log = xes_converter.apply(dataframe, variant=xes_converter.Variants.TO_EVENT_LOG) \n",
    "        logs.append(log)\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f89449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_cases(dataframes: [], no_of_cases:[]) -> []:\n",
    "    '''samples cases from the dataframes'''\n",
    "    \n",
    "    sampled_dfs = [0]*len(dataframes) # empty dataframes list to store sampled dataframes\n",
    "    sampled_dfs_idx = [] # marks the dataframe that has already been sampled\n",
    "    \n",
    "    # the percentage of cases to sample\n",
    "    for case_percentage in [0.10, 0.20, 0.30, 0.40, 0.50]:\n",
    "        for idx, dataframe in zip(range(0, len(no_of_cases)), dataframes):\n",
    "            # dataframe[idx] is not sampled\n",
    "            if idx not in sampled_dfs_idx:\n",
    "                if case_percentage != 0.50:\n",
    "                    #the dataframe has only one case, sampling not needed\n",
    "                    if no_of_cases[idx] == 1:\n",
    "                        sampled_dfs[idx] = dataframe\n",
    "                        sampled_dfs_idx.append(i)\n",
    "                    # sample cases based on percentage\n",
    "                    else:\n",
    "                        no_of_cases_to_sample = math.ceil(no_of_cases[i]*case_percentage)\n",
    "                        # use cminsampler to sample cases\n",
    "                        sampler = CminSampler(no_of_cases_to_sample)\n",
    "                        sampler.load_df(dataframe, constants.attr_case, constants.attr_event)\n",
    "                        sampled_cases = sampler.sample()\n",
    "                        # filter the dataframe only retaining the sampled cases\n",
    "                        sampled_df = dataframe[(dataframe[constants.attr_case].isin(sampled_cases))]\n",
    "                        # check how many unique equipments the sampling method covered\n",
    "                        all_unique_equipments = set(dataframe[constants.attr_event].to_list())\n",
    "                        sampled_unique_equipments = set(sampled_df[constants.attr_event].to_list())\n",
    "                        equipment_coverage = len(sampled_unique_equipments)/len(all_unique_equipments)\n",
    "                        # equipment coverage less than 80%, increase case percentage and sample again\n",
    "                        if equipment_coverage >= 0.80:\n",
    "                            # append the sampled dataframe to the list\n",
    "                            sampled_dfs[idx] = sampled_df\n",
    "                            # mark the dataframe as sampled\n",
    "                            sampled_dfs_idx.append(idx)\n",
    "                else:\n",
    "                    # case percentage 50%, stop sampling\n",
    "                    no_of_cases_to_sample = math.ceil(no_of_cases[idx]*case_percentage)\n",
    "                    sampler = CminSampler(no_of_cases_to_sample)\n",
    "                    sampler.load_df(dataframe, constants.attr_case, constants.attr_event)\n",
    "                    sampled_cases = sampler.sample()\n",
    "                    # filter the dataframe only retaining the sampled cases\n",
    "                    sampled_df = dataframe[(dataframe[constants.attr_case].isin(sampled_cases))]\n",
    "                    # append the sampled dataframe to the list\n",
    "                    sampled_dfs[idx] = sampled_df\n",
    "                    # mark the dataframe as sampled\n",
    "                    sampled_dfs_idx.append(i)\n",
    "    \n",
    "    return sampled_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = './2022_csv_rectified_logs' # contains all the csv data, change according to the name of the directory where files are saved\n",
    "# read the dataframes and convert to logs\n",
    "dataframes = read_dfs(lc.datafiles)\n",
    "logs = convert_to_logs(dataframes)\n",
    "# no of cases in each log\n",
    "no_of_cases = [len(log) for log in logs]\n",
    "# sample the dataframes\n",
    "sampled_dfs = sample_cases(dataframes, no_of_cases)\n",
    "# concatenate the sampled dataframes into one\n",
    "sampled_df = pd.concat(sampled_dfs)\n",
    "# convert the dataframe into logistic format\n",
    "sampled_df = fl.format_dataframe(sampled_df)\n",
    "# save the concatenated sampled dataframe\n",
    "sampled_df.to_csv('logistic_sampled.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
